{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlkzzVP9qUFw",
        "outputId": "2aec1f88-98e6-4936-c8ab-20c949ee8fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngram: . ngrams are sequences, Frequency: 1\n",
            "ngram: a sample text corpus, Frequency: 1\n",
            "ngram: are sequences of n-consecutive, Frequency: 1\n",
            "ngram: corpus used to generate, Frequency: 1\n",
            "ngram: generate ngrams . ngrams, Frequency: 1\n",
            "ngram: is a sample text, Frequency: 1\n",
            "ngram: ngrams . ngrams are, Frequency: 1\n",
            "ngram: ngrams are sequences of, Frequency: 1\n",
            "ngram: of n-consecutive words ., Frequency: 1\n",
            "ngram: sample text corpus used, Frequency: 1\n",
            "ngram: sequences of n-consecutive words, Frequency: 1\n",
            "ngram: text corpus used to, Frequency: 1\n",
            "ngram: this is a sample, Frequency: 1\n",
            "ngram: to generate ngrams ., Frequency: 1\n",
            "ngram: used to generate ngrams, Frequency: 1\n",
            "Next word after 'sample text corpus': 'used', Probability: 0.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"This is a sample text corpus used to generate ngrams. ngrams are sequences of n-consecutive words.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Initialize CountVectorizer for trigrams\n",
        "vectorizer = CountVectorizer(ngram_range=(4, 4), tokenizer=word_tokenize)\n",
        "ngram_matrix = vectorizer.fit_transform([text])\n",
        "\n",
        "# Get trigram names (features) from the vectorizer\n",
        "ngram_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert trigram matrix to a dictionary of trigram frequencies\n",
        "ngram_freq = dict(zip(ngram_names, ngram_matrix.toarray()[0]))\n",
        "for ngram, freq in ngram_freq.items():\n",
        "    print(f\"ngram: {ngram}, Frequency: {freq}\")\n",
        "\n",
        "def predict_next_word(mgram, ngram_freq):\n",
        "    \"\"\"\n",
        "    Predict the next word given a sequence of two words (bigram).\n",
        "    \"\"\"\n",
        "    mgram_str = ' '.join(mgram)\n",
        "    max_prob = 0\n",
        "    predicted_word = None\n",
        "\n",
        "    # Find the trigram with the highest probability that starts with the given bigram\n",
        "    for ngram, freq in ngram_freq.items():\n",
        "        if ngram.startswith(mgram_str):\n",
        "            probability = freq / sum(ngram_freq.values())\n",
        "            if probability > max_prob:\n",
        "                max_prob = probability\n",
        "                predicted_word = ngram.split()[-1]  # Get the last word of the trigram\n",
        "\n",
        "    return predicted_word, max_prob\n",
        "\n",
        "# Example: Predict next word after the bigram \"sample text\"\n",
        "mgram = [\"sample\", \"text\" , \"corpus\"]\n",
        "predicted_word, probability = predict_next_word(mgram, ngram_freq)\n",
        "\n",
        "print(f\"Next word after '{' '.join(mgram)}': '{predicted_word}', Probability: {probability:.2f}\")\n"
      ]
    }
  ]
}